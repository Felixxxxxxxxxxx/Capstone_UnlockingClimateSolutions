{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Collaboration Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Cities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In the following, we will assign values for each of the added features in an attempt to create a scoring system for the collaborative efforts of cities. \n",
    "\n",
    "More specifically, we will be looking at the columns `has_business_collaboration` and `collaboration_area`. \n",
    "\n",
    "Starting with `has_business_collaboration`, we will conduct a scoring from 1 to 5 with 1 being the lowest score which is attributed if there is no response given and 5 meaning that there is a business collaboration already in place. The scoring methodology is as follows:\n",
    "\n",
    "* 0: no response\n",
    "* 1: No / Not intending to undertake / Do not know\n",
    "* 2: Intending to undertake in future\n",
    "* 3: Intending to undertake in the next 2 years\n",
    "* 4: In progress\n",
    "* 5: Yes\n",
    "\n",
    "As for `collaboration_area` there is not enough information provided to make a clear and reliable distinction between the separate topics. However, following the idea of a holistic approach to address a climate change, we perceive that it is favorable if cities cooperate with businesses on multiple areas. Accordingly, we assign the following scores: \n",
    "\n",
    "* 0: no response\n",
    "* 1: one collaboration area\n",
    "* 2: two collaboration areas\n",
    "* 3: three collaboration areas\n",
    "* 4: four to five collaboration areas \n",
    "* 5: more that five collaboration areas\n",
    "\n",
    "Finally, we will aggregate the results in a final `city_collaboration_score` that will guide us in how well a particular city performs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### c_score_1 : City-Business Collaboration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign scores for each response option\n",
    "scores = {'nan': 0,\n",
    "          'No' :1, \n",
    "          'Not intending to undertake' :1,\n",
    "          'Do not know' :1,\n",
    "          'Intending to undertake in future':2,\n",
    "          'Intending to undertake in the next 2 years' :3,\n",
    "          'In progress':4,\n",
    "          'Yes':5}\n",
    "\n",
    "# create new business collaboration measure by mapping the scores to the respective response\n",
    "cid_new[\"has_business_collaboration_score\"] = cid_new[\"has_business_collaboration\"].map(scores)"
   ]
  },
  {
   "source": [
    "### c_score_2 : City_Business Collaboration Area"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a select key on which the information is mapped on\n",
    "cid_new[\"select_key\"] =cid_new[\"year\"].astype(str)+\"_\"+cid_new[\"account_number\"].astype(str)\n",
    "\n",
    "# compute the sum of entries of all individual collaboration areas and add each of them as new columns\n",
    "cid_new = cid_new.join(pd.crosstab(cid_new[\"select_key\"], cid_new[\"collaboration_area\"]), on=\"select_key\")\n",
    "\n",
    "# this computes the sum of all individual columns\n",
    "cid_new[\"sum_area\"] = cid_new.iloc[:,19:].sum(axis=1)\n",
    "\n",
    "# assign the respective score for each number of counts\n",
    "def create_score(x):\n",
    "        if x == 1:\n",
    "            return 1\n",
    "        elif x == 2:\n",
    "            return 2\n",
    "        elif x == 3:\n",
    "            return 3\n",
    "        elif x == 4 or x == 5:\n",
    "            return 4\n",
    "        elif x > 5:\n",
    "            return 5\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "cid_new[\"collaboration_area_score\"] = cid_new[\"sum_area\"].apply(create_score)\n",
    "\n",
    "#drop all helper columns from the dataframe\n",
    "cid_new.drop(['Other', 'Energy', 'Water', 'Waste', 'Transport',\n",
    "       'Industry', 'Agriculture and Forestry',\n",
    "       'Building and Infrastructure', 'Spatial Planning',\n",
    "       'Social Services', 'Business and Financial Services', 'sum_area'], axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### Final Collaboration Scoring Table for Cities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "cid_scores = cid_new[[\"account_number\", \"year\", \"has_business_collaboration_score\", \"collaboration_area_score\"]]\n",
    "# remove all duplicate entries that originate from the multi-row responses\n",
    "cid_scores.drop_duplicates(inplace=True)\n",
    "cid_scores.rename(columns={'has_business_collaboration_score': 'c_score_1', 'collaboration_area_score': 'c_score_2'}, inplace=True)cid_scores = cid_new[[\"account_number\", \"year\", \"has_business_collaboration_score\", \"collaboration_area_score\"]]\n",
    "# remove all duplicate entries that originate from the multi-row responses\n",
    "cid_scores.drop_duplicates(inplace=True)\n",
    "cid_scores.rename(columns={'has_business_collaboration_score': 'c_score_1', 'collaboration_area_score': 'c_score_2'}, inplace=True)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_scores.to_pickle(\"data/cid_scores.pkl\", protocol=4)"
   ]
  },
  {
   "source": [
    "## Corporates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Next, we will assign values for each of the added features in an attempt to create a scoring model for the collaborative efforts of corporates. \n",
    "\n",
    "More specifically, we will be looking at the columns `value_chain_engagement`, `customer_engagement`, `supply_chain_engagement`, and `policy_engagement`. \n",
    "\n",
    "Starting with `value_chain_engagement`, we will conduct a scoring from 1 to 5 with 1 being the lowest score which is attributed if there is no response given and 5 meaning that the company engages with both suppliers and customers. The scoring methodology is slightly more complicated compared to the previous models and is computed as follows:\n",
    "\n",
    "* 0: No response\n",
    "* 1: No, we do not engage\n",
    "* 2: Yes, our investee companies or Yes, other partners in our value chain while both Yes, our customers and Yes, our suppliers are not included\n",
    "* 3: Either Yes, our Suppliers or Yes, our Customers\n",
    "* 4: Both Yes, our Suppliers and Yes, our Customers\n",
    "* 5: All of Yes, our Supplier, Yes, our Customers and Yes, other partners in our value chain"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### c_score_3 : Corporate Value Chain Engagement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with value chain engagement responses\n",
    "df_value = cor.query(\"question_number == 'C12.1'\")[[\"account_number\", \"year\", \"entity\", \"response_answer\"]]\n",
    "\n",
    "# split response answer entries into individual response\n",
    "df_value = split_response(df=df_value, column=\"response_answer\", sep=\";\") \n",
    "df_value[\"response_answer\"] = df_value[\"response_answer\"].str.lstrip()\n",
    "\n",
    "# create select key for mapping the response\n",
    "df_value[\"select_key\"] =df_value[\"year\"].astype(str)+\"_\"+df_value[\"account_number\"].astype(str)\n",
    "cod_new[\"select_key\"] =cod_new[\"year\"].astype(str)+\"_\"+cod_new[\"account_number\"].astype(str)\n",
    "\n",
    "# compute the sum of entries of all individual collaboration areas and add each of them as new columns\n",
    "df_value = df_value.join(pd.crosstab(df_value[\"select_key\"], df_value[\"response_answer\"]), on=\"select_key\")\n",
    "\n",
    "# define a function to convert our response methodology to scores \n",
    "def conditions(s):\n",
    "    if s[\"No, we do not engage\"] >=1: \n",
    "        return 1\n",
    "    elif ((s[\"Yes, our investee companies\"] >=1) or (s[\"Yes, other partners in the value chain\"]>=1)) and ((s[\"Yes, our customers\"] == 0) and (s[\"Yes, our suppliers\"] == 0)): \n",
    "        return 2\n",
    "    elif ((s[\"Yes, our customers\"] >= 1) or (s[\"Yes, our suppliers\"] >= 1)) and ((s[\"Yes, our investee companies\"] == 0) and (s[\"Yes, other partners in the value chain\"]==0)): \n",
    "        return 3\n",
    "    elif ((s[\"Yes, our customers\"] >= 1) and (s[\"Yes, our suppliers\"] >= 1)) and ((s[\"Yes, our investee companies\"] == 0) and (s[\"Yes, other partners in the value chain\"]==0)): \n",
    "        return 4\n",
    "    elif ((s[\"Yes, our customers\"] >= 1) and (s[\"Yes, our suppliers\"] >= 1)) and ((s[\"Yes, our investee companies\"] >= 1) or (s[\"Yes, other partners in the value chain\"]>=1)): \n",
    "        return 5\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "# apply the function to create value chain scores\n",
    "df_value['value_chain_score'] = df_value.apply(conditions, axis=1)\n",
    "\n",
    "# create new dataframe with corporate collaboration scores including the new value chain score\n",
    "cod_scores = df_value[[\"account_number\", \"year\", \"value_chain_score\"]]\n",
    "\n",
    "# remove duplicate entries for each year\n",
    "cod_scores.drop_duplicates(inplace=True)"
   ]
  },
  {
   "source": [
    "### c_score_4: Corporate Supply Chain Engagement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supply = cor.query(\"question_number == 'C12.1a' and column_number == 1\")[[\"account_number\", \"year\", \"entity\", \"response_answer\"]]\n",
    "\n",
    "# Combine all the `other. please specify` responses into one `Other` category\n",
    "df_supply = df_supply.replace(df_supply.groupby('response_answer').sum().index[4:], 'Other')\n",
    "\n",
    "# define scoring system\n",
    "scores = {'NaN': 0,\n",
    "          'Compliance & onboarding' :1, \n",
    "          'Information collection (understanding supplier behavior)' :2,\n",
    "          'Engagement & incentivization (changing supplier behavior)':4,\n",
    "          'Innovation & collaboration (changing markets)' :5,\n",
    "          'Other':3}\n",
    "\n",
    "# maps scores to the respective response answer\n",
    "df_supply[\"supply_score\"] = df_supply[\"response_answer\"].map(scores)\n",
    "\n",
    "# choose max score for each entitiy in each year\n",
    "df_supply['supply_chain_score'] = df_supply.groupby(['account_number', 'year'])['supply_score'].transform(np.max)\n",
    "\n",
    "# create merge keys\n",
    "df_supply[\"select_key\"] = df_supply[\"year\"].astype(str) + \"_\" + df_supply[\"account_number\"].astype(str)\n",
    "cod_scores[\"select_key\"] = cod_scores[\"year\"].astype(str) + \"_\" + cod_scores[\"account_number\"].astype(str)\n",
    "\n",
    "# merge new supply chain score to disclosure dataframe\n",
    "cod_scores = pd.merge(left=cod_scores,\n",
    "                   right= df_supply[\"supply_chain_score\"],\n",
    "                   left_on=cod_scores[\"select_key\"],\n",
    "                   right_on=df_supply[\"select_key\"],\n",
    "                   how=\"left\")\n",
    "cod_scores.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop the unneccessary columns\n",
    "cod_scores.drop(\"key_0\", axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### c_score_5: Corporate Customer Engagement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = cor.query(\"question_number == 'C12.1b' and column_number == 1\")[[\"account_number\", \"year\", \"entity\", \"response_answer\"]]\n",
    "\n",
    "# replace all of the individual \"other\" specifications into a single \"other\" group\n",
    "df_customer = df_customer.replace(df_customer.groupby('response_answer').sum().index[5:], 'Other')\n",
    "\n",
    "# we merge the two Education/information sharing response options into one response\n",
    "df_customer[\"response_answer\"] = df_customer['response_answer'].str.replace('Education/information sharing : Engagement','Education/information sharing')\n",
    "\n",
    "# we assign values for each response option\n",
    "scores = {'nan': 0, \n",
    "          'Information collection (understanding customer behavior)' :1,\n",
    "          'Education/information sharing' : 2,\n",
    "          'Engagement & incentivization (changing customer behavior)':4,\n",
    "          'Collaboration & innovation' :5,\n",
    "          'Other':3}\n",
    "\n",
    "# maps scores to the respective response answer\n",
    "df_customer[\"customer_score\"] = df_customer[\"response_answer\"].map(scores)\n",
    "\n",
    "# choose max score for each entitiy in each year\n",
    "df_customer['customer_score'] = df_customer.groupby(['account_number', 'year'])['customer_score'].transform(np.max)\n",
    "\n",
    "# create select key for merging to disclosure dataframe\n",
    "df_customer[\"select_key\"] = df_customer[\"year\"].astype(str)+\"_\"+df_customer[\"account_number\"].astype(str)\n",
    "\n",
    "# create select key for merging to collaboration scoring dataframe\n",
    "df_customer[\"select_key\"] = df_customer[\"year\"].astype(str)+\"_\"+df_customer[\"account_number\"].astype(str)\n",
    "\n",
    "# merge new supply chain score to disclosure dataframe\n",
    "cod_scores = pd.merge(left=cod_scores,\n",
    "                   right= df_customer[\"customer_score\"],\n",
    "                   left_on=cod_scores[\"select_key\"],\n",
    "                   right_on=df_customer[\"select_key\"],\n",
    "                   how=\"left\")\n",
    "cod_scores.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop the unneccessary columns\n",
    "cod_scores.drop(\"key_0\", axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### c_score_6: Corporate Policy Engagement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Here, the scoring is a little more compicated and even more subjective compared to the other value chain engagement scores. \n",
    "Again, we follow our perspective that climate resilience is enhanced when businesses and policy makers work together rather than alone. However, as denoted by the think tank InfluenceMap, only few of the influential corporations are positively engaging on climate policy globally, with most holding either a neutral or negative perspective. This makes a coherent scoring more difficult. One the one hand side, we intend to promote purposeful engagement of corporates with policy makers. On the other hand-side, we only perceive those policy engagements as positive where businesses support the view of local policy makers. Unfortunately, the data provided offers this information for the response option *Direct engagment with policy makers*.\n",
    "\n",
    "To account for this view, we focus on the direct engagement with policy makers and combine the response with the corporate position with policy decisions. Ultimately, we apply the following scoring methodology:\n",
    "\n",
    "* 1: No\n",
    "* 2: Trade associations / Funding research organizations / Direct engagement with policy makers & either no corporate position provided or position is opposing/neutral/undecided \n",
    "* 3: Direct engagement with policy makers & support with major exceptions\n",
    "* 4: Direct engagmenet with policy makers & support with minor exceptions\n",
    "* 5: Direct engagement with policy makers & supportive corporate position"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract question from response dataset into separate dataframe\n",
    "df_policy = cor.query(\"question_number == 'C12.3'\")[[\"account_number\", \"year\", \"entity\", \"response_answer\"]]\n",
    "\n",
    "# split chained response answers\n",
    "df_policy = split_response(df=df_policy, column=\"response_answer\".lstrip(), sep=\";\")\n",
    "\n",
    "# remove whitespaces infront of response options\n",
    "df_policy[\"response_answer\"] = df_policy[\"response_answer\"].str.lstrip()\n",
    "\n",
    "# create select key to match information\n",
    "df_policy[\"select_key\"] =df_policy[\"year\"].astype(str)+\"_\"+df_policy[\"account_number\"].astype(str)\n",
    "\n",
    "# create new dataframe for the corporate position\n",
    "df_position = cor.query(\"question_number == 'C12.3a' and column_number == 2\")[[\"account_number\", \"year\", \"response_answer\"]]\n",
    "\n",
    "# create merge key\n",
    "df_position[\"select_key\"] =df_position[\"year\"].astype(str)+\"_\"+df_position[\"account_number\"].astype(str)\n",
    "\n",
    "# convert response options to columns\n",
    "df_position = df_position.join(pd.crosstab(df_position[\"select_key\"], df_position[\"response_answer\"]), on=df_position[\"select_key\"])\n",
    "\n"
   ]
  },
  {
   "source": [
    "**Note:**\n",
    "\n",
    "In the next step, we create a helper column that defines the majority position that a companies takes on policy views. This is necessary given that it is a multi-response column, thus, a single company can have multiple position in a year. This is because each position is assigned to a policy topic (e.g. Energy). For simplification purposes, we take the majority position that a corporate holds in a year. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper column with majority position\n",
    "df_position[\"majority_position\"] = df_position[[\"Neutral\", \"Oppose\", \"Support\", \"Support with major exceptions\", \"Support with minor exceptions\", \"Undecided\"]].idxmax(1)\n",
    "\n",
    "# merge majority position to policy dataframe\n",
    "df_policy = pd.merge(left=df_policy,\n",
    "                   right= df_position[\"majority_position\"],\n",
    "                   left_on=df_policy[\"select_key\"],\n",
    "                   right_on=df_position[\"select_key\"],\n",
    "                   how=\"left\")\n",
    "df_policy.drop_duplicates(inplace=True)\n",
    "\n",
    "# define the conditions based on which scores are assigned\n",
    "conditions = [df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Support\"), \n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Oppose\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Undecided\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Neutral\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"NaN\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Support with minor exceptions\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Support with major exceptions\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Funding research organizations\") | df_policy[\"response_answer\"].eq(\"Trade associations\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Other\"),\n",
    "              df_policy[\"response_answer\"].eq(\"No\")]\n",
    "\n",
    "choices = [5, 2, 2, 2, 2, 4, 3, 2, 2, 1]\n",
    "\n",
    "df_policy[\"policy_score\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "# choose max score for each entitiy in each year\n",
    "df_policy['policy_score'] = df_policy.groupby(['account_number', 'year'])['policy_score'].transform(np.max)\n",
    "\n",
    "# merge final policy score results to collaboration scoring dataframe\n",
    "cod_scores = pd.merge(left=cod_scores,\n",
    "                   right= df_policy[\"policy_score\"],\n",
    "                   left_on=cod_scores[\"select_key\"],\n",
    "                   right_on=df_policy[\"select_key\"],\n",
    "                   how=\"left\")\n",
    "cod_scores.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop the unneccessary columns\n",
    "cod_scores.drop(\"key_0\", axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### Final Collaboration Scoring Table for Corporates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_scores.rename(columns={'value_chain_score': 'c_score_3', 'customer_score': 'c_score_4', 'supply_chain_score': 'c_score_5', 'policy_score': 'c_score_6'}, inplace=True)\n",
    "cod_scores.drop(\"select_key\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_scores.to_pickle(\"data/cod_scores.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}